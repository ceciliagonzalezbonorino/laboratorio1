{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "82397e17-dc2f-435d-85ff-ca51309adeec",
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"dataframe\">\n",
       "<caption>A matrix: 2 × 6 of type dbl</caption>\n",
       "<thead>\n",
       "\t<tr><th></th><th scope=col>used</th><th scope=col>(Mb)</th><th scope=col>gc trigger</th><th scope=col>(Mb)</th><th scope=col>max used</th><th scope=col>(Mb)</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "\t<tr><th scope=row>Ncells</th><td>  2786815</td><td>148.9</td><td>  4421061</td><td> 236.2</td><td>   4421061</td><td>  236.2</td></tr>\n",
       "\t<tr><th scope=row>Vcells</th><td>103887789</td><td>792.7</td><td>301983357</td><td>2304.0</td><td>1895294934</td><td>14460.0</td></tr>\n",
       "</tbody>\n",
       "</table>\n"
      ],
      "text/latex": [
       "A matrix: 2 × 6 of type dbl\n",
       "\\begin{tabular}{r|llllll}\n",
       "  & used & (Mb) & gc trigger & (Mb) & max used & (Mb)\\\\\n",
       "\\hline\n",
       "\tNcells &   2786815 & 148.9 &   4421061 &  236.2 &    4421061 &   236.2\\\\\n",
       "\tVcells & 103887789 & 792.7 & 301983357 & 2304.0 & 1895294934 & 14460.0\\\\\n",
       "\\end{tabular}\n"
      ],
      "text/markdown": [
       "\n",
       "A matrix: 2 × 6 of type dbl\n",
       "\n",
       "| <!--/--> | used | (Mb) | gc trigger | (Mb) | max used | (Mb) |\n",
       "|---|---|---|---|---|---|---|\n",
       "| Ncells |   2786815 | 148.9 |   4421061 |  236.2 |    4421061 |   236.2 |\n",
       "| Vcells | 103887789 | 792.7 | 301983357 | 2304.0 | 1895294934 | 14460.0 |\n",
       "\n"
      ],
      "text/plain": [
       "       used      (Mb)  gc trigger (Mb)   max used   (Mb)   \n",
       "Ncells   2786815 148.9   4421061   236.2    4421061   236.2\n",
       "Vcells 103887789 792.7 301983357  2304.0 1895294934 14460.0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#limpio la memoria\n",
    "rm( list=ls() )  #remove all objects\n",
    "gc()             #garbage collection\n",
    "\n",
    "require(\"data.table\")\n",
    "require(\"rlist\")\n",
    "\n",
    "require(\"lightgbm\")\n",
    "\n",
    "#paquetes necesarios para la Bayesian Optimization\n",
    "require(\"DiceKriging\")\n",
    "require(\"mlrMBO\")\n",
    "\n",
    "\n",
    "#Parametros del script\n",
    "kexperimento  <- \"HT7412_1mes\"\n",
    "kexp_input  <- \"TS7312_1mes\"\n",
    "# FIN Parametros del script\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "94fad56e-1a40-4824-9982-126c3ce684f9",
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "#------------------------------------------------------------------------------\n",
    "options(error = function() { \n",
    "  traceback(20); \n",
    "  options(error = NULL); \n",
    "  stop(\"exiting after script error\") \n",
    "})\n",
    "#------------------------------------------------------------------------------\n",
    "\n",
    "ksemilla  <- 690621\n",
    "\n",
    "kcrossvalidation_folds  <- 5  #En caso que se haga cross validation, se usa esta cantidad de folds\n",
    "\n",
    "#Hiperparametros FIJOS de  lightgbm\n",
    "param_lgb_basicos  <- list( \n",
    "   boosting= \"gbdt\",          #puede ir  dart  , ni pruebe random_forest\n",
    "   objective= \"binary\",\n",
    "   metric= \"custom\",\n",
    "   first_metric_only= TRUE,\n",
    "   boost_from_average= TRUE,\n",
    "   feature_pre_filter= FALSE,\n",
    "   force_row_wise= TRUE,      #para que los alumnos no se atemoricen con tantos warning\n",
    "   verbosity= -100,\n",
    "   max_depth=  -1,            # -1 significa no limitar,  por ahora lo dejo fijo\n",
    "   min_gain_to_split= 0.0,    #por ahora, lo dejo fijo\n",
    "   lambda_l1= 0.0,            #por ahora, lo dejo fijo\n",
    "   lambda_l2= 0.0,            #por ahora, lo dejo fijo\n",
    "   max_bin= 31,               #por ahora, lo dejo fijo\n",
    "   num_iterations= 9999,      #un numero muy grande, lo limita early_stopping_rounds\n",
    "\n",
    "   bagging_fraction= 1.0,     #por ahora, lo dejo fijo\n",
    "   pos_bagging_fraction= 1.0, #por ahora, lo dejo fijo\n",
    "   neg_bagging_fraction= 1.0, #por ahora, lo dejo fijo\n",
    "\n",
    "   drop_rate=  0.1,           #solo se activa en  dart\n",
    "   max_drop= 50,              #solo se activa en  dart\n",
    "   skip_drop= 0.5,            #solo se activa en  dart\n",
    "\n",
    "   extra_trees= FALSE,\n",
    "\n",
    "   seed=  ksemilla\n",
    "   )\n",
    "\n",
    "\n",
    "#Aqui se cargan los hiperparametros que se optimizan en la Bayesian Optimization\n",
    "hs <- makeParamSet( \n",
    "         makeNumericParam(\"learning_rate\",    lower=    0.005, upper=    0.3),\n",
    "         makeNumericParam(\"feature_fraction\", lower=    0.2  , upper=    1.0),\n",
    "         makeIntegerParam(\"min_data_in_leaf\", lower=    0L   , upper=  8000L),\n",
    "         makeIntegerParam(\"num_leaves\",       lower=   16L   , upper=  2048L)\n",
    "        )\n",
    "\n",
    "\n",
    "#si usted es ambicioso, y tiene paciencia, podria subir este valor a 100\n",
    "kBO_iteraciones  <- 50  #iteraciones de la Optimizacion Bayesiana\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "08595763-fcca-4931-bd82-0b52c6bf7a61",
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "#------------------------------------------------------------------------------\n",
    "#graba a un archivo los componentes de lista\n",
    "#para el primer registro, escribe antes los titulos\n",
    "\n",
    "exp_log  <- function( reg, arch=NA, folder=\"./exp/\", ext=\".txt\", verbose=TRUE )\n",
    "{\n",
    "  archivo  <- arch\n",
    "  if( is.na(arch) )  archivo  <- paste0(  folder, substitute( reg), ext )\n",
    "\n",
    "  if( !file.exists( archivo ) )  #Escribo los titulos\n",
    "  {\n",
    "    linea  <- paste0( \"fecha\\t\", \n",
    "                      paste( list.names(reg), collapse=\"\\t\" ), \"\\n\" )\n",
    "\n",
    "    cat( linea, file=archivo )\n",
    "  }\n",
    "\n",
    "  linea  <- paste0( format(Sys.time(), \"%Y%m%d %H%M%S\"),  \"\\t\",     #la fecha y hora\n",
    "                    gsub( \", \", \"\\t\", toString( reg ) ),  \"\\n\" )\n",
    "\n",
    "  cat( linea, file=archivo, append=TRUE )  #grabo al archivo\n",
    "\n",
    "  if( verbose )  cat( linea )   #imprimo por pantalla\n",
    "}\n",
    "\n",
    "#------------------------------------------------------------------------------\n",
    "\n",
    "vprob_optima  <- c()\n",
    "\n",
    "fganancia_lgbm_meseta  <- function( probs, datos) \n",
    "{\n",
    "  vlabels  <- get_field(datos, \"label\")\n",
    "\n",
    "  tbl  <- as.data.table( list( \"prob\"= probs, \n",
    "                               \"gan\" = ifelse( vlabels==1 , 78000, -2000  ) ) )\n",
    "\n",
    "  setorder( tbl, -prob )\n",
    "  tbl[ , posicion := .I ]\n",
    "  tbl[ , gan_acum :=  cumsum( gan ) ]\n",
    "\n",
    "  gan  <-  tbl[ , max(gan_acum) ]\n",
    "\n",
    "  pos  <- which.max(  tbl[ , gan_acum ] ) \n",
    "  vprob_optima  <<- c( vprob_optima, tbl[ pos, prob ] )\n",
    "\n",
    "  rm( tbl )\n",
    "  return( list( \"name\"= \"ganancia\", \n",
    "                \"value\"=  gan,\n",
    "                \"higher_better\"= TRUE ) )\n",
    "}\n",
    "#------------------------------------------------------------------------------\n",
    "\n",
    "EstimarGanancia_lightgbm  <- function( x )\n",
    "{\n",
    "  gc()\n",
    "  GLOBAL_iteracion  <<- GLOBAL_iteracion + 1\n",
    "\n",
    "  param_completo  <- c( param_lgb_basicos,  x )\n",
    "\n",
    "  param_completo$early_stopping_rounds  <- as.integer(200 + 4/param_completo$learning_rate )\n",
    "\n",
    "  vprob_optima  <<- c()\n",
    "  set.seed( param_completo$seed )\n",
    "  modelo_train  <- lgb.train( data= dtrain,\n",
    "                              valids= list( valid= dvalidate ),\n",
    "                              eval=   fganancia_lgbm_meseta,\n",
    "                              param=  param_completo,\n",
    "                              verbose= -100 )\n",
    "\n",
    "  prob_corte  <- vprob_optima[ modelo_train$best_iter ]\n",
    "\n",
    "  #aplico el modelo a testing y calculo la ganancia\n",
    "  prediccion  <- predict( modelo_train, \n",
    "                          data.matrix( dataset_test[ , campos_buenos, with=FALSE]) )\n",
    "\n",
    "  tbl  <- dataset_test[ , list(clase_ternaria) ]\n",
    "  tbl[ , prob := prediccion ]\n",
    "  ganancia_test  <- tbl[ prob >= prob_corte, \n",
    "                         sum( ifelse(clase_ternaria==\"BAJA+2\", 78000, -2000 ) )]\n",
    "\n",
    "  cantidad_test_normalizada  <- tbl[ prob >= prob_corte, .N ]\n",
    "\n",
    "  rm( tbl )\n",
    "  gc()\n",
    "\n",
    "  ganancia_test_normalizada  <- ganancia_test\n",
    "\n",
    "\n",
    "  #voy grabando las mejores column importance\n",
    "  if( ganancia_test_normalizada >  GLOBAL_ganancia )\n",
    "  {\n",
    "    GLOBAL_ganancia  <<- ganancia_test_normalizada\n",
    "    tb_importancia    <- as.data.table( lgb.importance( modelo_train ) )\n",
    "\n",
    "    fwrite( tb_importancia,\n",
    "            file= paste0( \"impo_\", GLOBAL_iteracion, \".txt\" ),\n",
    "            sep= \"\\t\" )\n",
    "\n",
    "    rm( tb_importancia )\n",
    "  }\n",
    "\n",
    "\n",
    "  #logueo final\n",
    "  ds  <- list( \"cols\"= ncol(dtrain),  \"rows\"= nrow(dtrain) )\n",
    "  xx  <- c( ds, copy(param_completo) )\n",
    "\n",
    "  xx$early_stopping_rounds  <- NULL\n",
    "  xx$num_iterations  <- modelo_train$best_iter\n",
    "  xx$prob_corte  <- prob_corte\n",
    "  xx$estimulos  <- cantidad_test_normalizada\n",
    "  xx$ganancia  <- ganancia_test_normalizada\n",
    "  xx$iteracion_bayesiana  <- GLOBAL_iteracion\n",
    "\n",
    "  exp_log( xx,  arch= \"BO_log_1mes.txt\" )\n",
    "\n",
    "  return( ganancia_test_normalizada )\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "89e35473-58c5-4b64-aa87-497e16ff434a",
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "#------------------------------------------------------------------------------\n",
    "#esta es la funcion mas mistica de toda la asignatura\n",
    "# sera explicada en  Laboratorio de Implementacion III\n",
    "\n",
    "vprob_optima  <- c()\n",
    "vpos_optima   <- c()\n",
    "\n",
    "fganancia_lgbm_mesetaCV  <- function( probs, datos) \n",
    "{\n",
    "  vlabels  <- get_field(datos, \"label\")\n",
    "  vpesos   <- get_field(datos, \"weight\")\n",
    "\n",
    "  tbl  <- as.data.table( list( \"prob\"= probs, \n",
    "                               \"gan\" = ifelse( vlabels==1 & vpesos > 1,\n",
    "                                               78000,\n",
    "                                               -2000  ) ) )\n",
    "\n",
    "  setorder( tbl, -prob )\n",
    "  tbl[ , posicion := .I ]\n",
    "  tbl[ , gan_acum :=  cumsum( gan ) ]\n",
    "\n",
    "  gan  <-  tbl[ , max(gan_acum) ]\n",
    "\n",
    "  pos  <- which.max(  tbl[ , gan_acum ] ) \n",
    "  vpos_optima   <<- c( vpos_optima, pos )\n",
    "  vprob_optima  <<- c( vprob_optima, tbl[ pos, prob ] )\n",
    "\n",
    "  rm( tbl )\n",
    "  return( list( \"name\"= \"ganancia\", \n",
    "                \"value\"=  gan,\n",
    "                \"higher_better\"= TRUE ) )\n",
    "}\n",
    "#------------------------------------------------------------------------------\n",
    "\n",
    "EstimarGanancia_lightgbmCV  <- function( x )\n",
    "{\n",
    "  gc()\n",
    "  GLOBAL_iteracion  <<- GLOBAL_iteracion + 1\n",
    "\n",
    "  param_completo  <- c(param_lgb_basicos,  x )\n",
    "\n",
    "  param_completo$early_stopping_rounds  <- as.integer(200 + 4/param_completo$learning_rate )\n",
    "\n",
    "  vprob_optima  <<- c()\n",
    "  vpos_optima   <<- c()\n",
    "\n",
    "  set.seed( param_completo$seed )\n",
    "  modelocv  <- lgb.cv( data= dtrain,\n",
    "                       eval=   fganancia_lgbm_mesetaCV,\n",
    "                       param=  param_completo,\n",
    "                       stratified= TRUE,                   #sobre el cross validation\n",
    "                       nfold= kcrossvalidation_folds,\n",
    "                       verbose= -100 )\n",
    "\n",
    "  desde  <- (modelocv$best_iter-1)*kcrossvalidation_folds + 1\n",
    "  hasta  <- desde + kcrossvalidation_folds -1\n",
    "\n",
    "  prob_corte            <-  mean( vprob_optima[ desde:hasta ] )\n",
    "  cantidad_normalizada  <-  mean( vpos_optima[ desde:hasta ] ) * kcrossvalidation_folds\n",
    "\n",
    "  ganancia  <- unlist(modelocv$record_evals$valid$ganancia$eval)[ modelocv$best_iter ]\n",
    "  ganancia_normalizada  <- ganancia * kcrossvalidation_folds\n",
    "\n",
    "\n",
    "  #voy grabando las mejores column importance\n",
    "  if( ganancia_normalizada >  GLOBAL_ganancia )\n",
    "  {\n",
    "    GLOBAL_ganancia  <<- ganancia_normalizada\n",
    "\n",
    "    param_impo <-  copy( param_completo )\n",
    "    param_impo$early_stopping_rounds  <- 0\n",
    "    param_impo$num_iterations  <- modelocv$best_iter\n",
    "\n",
    "    modelo  <- lgb.train( data= dtrain,\n",
    "                       param=  param_impo,\n",
    "                       verbose= -100 )\n",
    "\n",
    "    tb_importancia    <- as.data.table( lgb.importance( modelo ) )\n",
    "\n",
    "    fwrite( tb_importancia,\n",
    "            file= paste0( \"impo_\", GLOBAL_iteracion, \".txt\" ),\n",
    "            sep= \"\\t\" )\n",
    "    \n",
    "    rm( tb_importancia )\n",
    "  }\n",
    "\n",
    "\n",
    "  #logueo final\n",
    "  ds  <- list( \"cols\"= ncol(dtrain),  \"rows\"= nrow(dtrain) )\n",
    "  xx  <- c( ds, copy(param_completo) )\n",
    "\n",
    "  xx$early_stopping_rounds  <- NULL\n",
    "  xx$num_iterations  <- modelocv$best_iter\n",
    "  xx$prob_corte  <-  prob_corte\n",
    "  xx$estimulos   <-  cantidad_normalizada\n",
    "  xx$ganancia  <- ganancia_normalizada\n",
    "  xx$iteracion_bayesiana  <- GLOBAL_iteracion\n",
    "\n",
    "  exp_log( xx,  arch= \"BO_log_1mes.txt\" )\n",
    "\n",
    "  return( ganancia_normalizada )\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3d77b787-4050-497e-93b7-0e38f4ba9588",
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "setwd(\"~/buckets/b1/\")\n",
    "#cargo el dataset donde voy a entrenar\n",
    "#esta en la carpeta del exp_input y siempre se llama  dataset_training.csv.gz\n",
    "dataset  <- fread(\"exp/TS7310/dataset_training.csv.gz\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "20ac47ea-33ee-48f9-a781-032c9700610c",
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning message in `[.data.table`(dataset, , `:=`(clase01, ifelse(clase_ternaria == :\n",
      "“Invalid .internal.selfref detected and fixed by taking a (shallow) copy of the data.table so that := can add this new column by reference. At an earlier point, this data.table has been copied by R (or was created manually using structure() or similar). Avoid names<- and attr<- which in R currently (and oddly) may copy the whole data.table. Use set* syntax instead to avoid copying: ?set, ?setnames and ?setattr. If this message doesn't help, please report your use case to the data.table issue tracker so the root cause can be fixed or this message improved.”\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table class=\"dataframe\">\n",
       "<caption>A matrix: 2 × 6 of type dbl</caption>\n",
       "<thead>\n",
       "\t<tr><th></th><th scope=col>used</th><th scope=col>(Mb)</th><th scope=col>gc trigger</th><th scope=col>(Mb)</th><th scope=col>max used</th><th scope=col>(Mb)</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "\t<tr><th scope=row>Ncells</th><td>  2787820</td><td>148.9</td><td>   4421061</td><td> 236.2</td><td>   4421061</td><td>  236.2</td></tr>\n",
       "\t<tr><th scope=row>Vcells</th><td>101352688</td><td>773.3</td><td>1261342645</td><td>9623.3</td><td>1969032230</td><td>15022.6</td></tr>\n",
       "</tbody>\n",
       "</table>\n"
      ],
      "text/latex": [
       "A matrix: 2 × 6 of type dbl\n",
       "\\begin{tabular}{r|llllll}\n",
       "  & used & (Mb) & gc trigger & (Mb) & max used & (Mb)\\\\\n",
       "\\hline\n",
       "\tNcells &   2787820 & 148.9 &    4421061 &  236.2 &    4421061 &   236.2\\\\\n",
       "\tVcells & 101352688 & 773.3 & 1261342645 & 9623.3 & 1969032230 & 15022.6\\\\\n",
       "\\end{tabular}\n"
      ],
      "text/markdown": [
       "\n",
       "A matrix: 2 × 6 of type dbl\n",
       "\n",
       "| <!--/--> | used | (Mb) | gc trigger | (Mb) | max used | (Mb) |\n",
       "|---|---|---|---|---|---|---|\n",
       "| Ncells |   2787820 | 148.9 |    4421061 |  236.2 |    4421061 |   236.2 |\n",
       "| Vcells | 101352688 | 773.3 | 1261342645 | 9623.3 | 1969032230 | 15022.6 |\n",
       "\n"
      ],
      "text/plain": [
       "       used      (Mb)  gc trigger (Mb)   max used   (Mb)   \n",
       "Ncells   2787820 148.9    4421061  236.2    4421061   236.2\n",
       "Vcells 101352688 773.3 1261342645 9623.3 1969032230 15022.6"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Verificaciones\n",
    "if( ! (\"fold_train\"    %in% colnames(dataset) ) ) stop(\"Error, el dataset no tiene el campo fold_train \\n\")\n",
    "if( ! (\"fold_validate\" %in% colnames(dataset) ) ) stop(\"Error, el dataset no tiene el campo fold_validate \\n\")\n",
    "if( ! (\"fold_test\"     %in% colnames(dataset) ) ) stop(\"Error, el dataset no tiene el campo fold_test  \\n\")\n",
    "if( dataset[ fold_train==1, .N ] == 0 ) stop(\"Error, en el dataset no hay fold_train==1 \\n\")\n",
    "\n",
    "#creo la carpeta donde va el experimento\n",
    "dir.create( paste0( \"./exp/\", kexperimento, \"/\"), showWarnings = FALSE )\n",
    "setwd(paste0( \"./exp/\", kexperimento, \"/\"))   #Establezco el Working Directory DEL EXPERIMENTO\n",
    "\n",
    "cat( kexp_input,\n",
    "     file= \"TrainingStrategy.txt\",\n",
    "     append= FALSE )\n",
    "\n",
    "#defino la clase binaria clase01\n",
    "dataset[  , clase01 := ifelse( clase_ternaria==\"CONTINUA\", 0L, 1L ) ]\n",
    "\n",
    "\n",
    "#los campos que se pueden utilizar para la prediccion\n",
    "campos_buenos  <- setdiff( copy(colnames( dataset )), c( \"clase01\", \"clase_ternaria\", \"fold_train\", \"fold_validate\", \"fold_test\" ) )\n",
    "\n",
    "#la particion de train siempre va\n",
    "dtrain  <- lgb.Dataset( data=    data.matrix( dataset[ fold_train==1, campos_buenos, with=FALSE] ),\n",
    "                        label=   dataset[ fold_train==1, clase01 ],\n",
    "                        weight=  dataset[ fold_train==1, ifelse( clase_ternaria == \"BAJA+2\", 1.0000001, 1.0) ],\n",
    "                        free_raw_data= FALSE\n",
    "                      )\n",
    "\n",
    "\n",
    "kvalidate  <- FALSE\n",
    "ktest  <- FALSE\n",
    "kcrossvalidation  <- TRUE\n",
    "\n",
    "#Si hay que hacer validacion\n",
    "if( dataset[ fold_train==0 & fold_test==0 & fold_validate==1, .N ] > 0 )\n",
    "{\n",
    "  kcrossvalidation  <- FALSE\n",
    "  kvalidate  <- TRUE\n",
    "  dvalidate  <- lgb.Dataset( data=  data.matrix( dataset[ fold_validate==1, campos_buenos, with=FALSE] ),\n",
    "                             label= dataset[ fold_validate==1, clase01 ],\n",
    "                             free_raw_data= FALSE  )\n",
    "\n",
    "}\n",
    "\n",
    "#Si hay que hacer testing\n",
    "if( dataset[ fold_train==0 & fold_validate==0 & fold_test==1, .N ] > 0 )\n",
    "{\n",
    "  ktest  <- TRUE\n",
    "  kcrossvalidation  <- FALSE\n",
    "  dataset_test  <- dataset[ fold_test== 1 ]\n",
    "}\n",
    "\n",
    "\n",
    "#Si hay testing, sin validation,  STOP !!\n",
    "if( kvalidate== FALSE & ktest== TRUE ) stop(\"Error, si hay testing, debe haber validation \\n\") \n",
    "\n",
    "\n",
    "rm( dataset )\n",
    "gc()\n",
    "\n",
    "\n",
    "#si ya existe el archivo log, traigo hasta donde procese\n",
    "if( file.exists( \"BO_log_1mes.txt\" ) )\n",
    "{\n",
    "  tabla_log  <- fread( \"BO_log_1mes.txt\" )\n",
    "  GLOBAL_iteracion  <- nrow( tabla_log )\n",
    "  GLOBAL_ganancia   <- tabla_log[ , max(ganancia) ]\n",
    "  rm(tabla_log)\n",
    "} else  {\n",
    "  GLOBAL_iteracion  <- 0\n",
    "  GLOBAL_ganancia   <- -Inf\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "cd846eb4-cd70-4bb0-ba4e-35b19c2305e5",
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning message in mboContinue(\"bayesiana.RDATA\"):\n",
      "“Tuning ended with term.iter. No need to continue. Simply returning stored result.”\n"
     ]
    }
   ],
   "source": [
    "#Aqui comienza la configuracion de mlrMBO\n",
    "\n",
    "#deobo hacer cross validation o  Train/Validate/Test\n",
    "if( kcrossvalidation ) {\n",
    "  funcion_optimizar  <- EstimarGanancia_lightgbmCV\n",
    "} else {\n",
    "  funcion_optimizar  <- EstimarGanancia_lightgbm\n",
    "}\n",
    "\n",
    "\n",
    "configureMlr( show.learner.output= FALSE)\n",
    "\n",
    "#configuro la busqueda bayesiana,  los hiperparametros que se van a optimizar\n",
    "#por favor, no desesperarse por lo complejo\n",
    "obj.fun  <- makeSingleObjectiveFunction(\n",
    "              fn=       funcion_optimizar, #la funcion que voy a maximizar\n",
    "              minimize= FALSE,   #estoy Maximizando la ganancia\n",
    "              noisy=    TRUE,\n",
    "              par.set=  hs,     #definido al comienzo del programa\n",
    "              has.simple.signature = FALSE   #paso los parametros en una lista\n",
    "             )\n",
    "\n",
    "#archivo donde se graba y cada cuantos segundos\n",
    "ctrl  <- makeMBOControl( save.on.disk.at.time= 600,  \n",
    "                         save.file.path=       \"bayesiana.RDATA\" )\n",
    "                         \n",
    "ctrl  <- setMBOControlTermination( ctrl, \n",
    "                                   iters= kBO_iteraciones )   #cantidad de iteraciones\n",
    "                                   \n",
    "ctrl  <- setMBOControlInfill(ctrl, crit= makeMBOInfillCritEI() )\n",
    "\n",
    "#establezco la funcion que busca el maximo\n",
    "surr.km  <- makeLearner(\"regr.km\",\n",
    "                        predict.type= \"se\",\n",
    "                        covtype= \"matern3_2\",\n",
    "                        control= list(trace= TRUE) )\n",
    "\n",
    "\n",
    "\n",
    "#Aqui inicio la optimizacion bayesiana\n",
    "if( !file.exists( \"bayesiana.RDATA\" ) ) {\n",
    "\n",
    "  run  <- mbo(obj.fun, learner= surr.km, control= ctrl)\n",
    "\n",
    "} else {\n",
    "  #si ya existe el archivo RDATA, debo continuar desde el punto hasta donde llegue\n",
    "  #  usado para cuando se corta la virtual machine\n",
    "  run  <- mboContinue( \"bayesiana.RDATA\" )   #retomo en caso que ya exista\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6868d72e-503e-45a6-bda6-6ef0dba2fc48",
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "R",
   "language": "R",
   "name": "ir"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "4.2.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
