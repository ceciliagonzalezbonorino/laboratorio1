{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59f6ed1c-f9c9-47d0-81b1-fec81af396ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Necesita para correr en Google Cloud\n",
    "# 128 GB de memoria RAM\n",
    "# 256 GB de espacio en el disco local\n",
    "#   8 vCPU\n",
    "\n",
    "\n",
    "#limpio la memoria\n",
    "rm( list=ls() )  #remove all objects\n",
    "gc()             #garbage collection\n",
    "\n",
    "require(\"data.table\")\n",
    "\n",
    "require(\"lightgbm\")\n",
    "\n",
    "#Parametros del script\n",
    "kexperimento  <- \"ZZ9414\"\n",
    "kexp_input  <- \"HT7412_5meses\"\n",
    "\n",
    "kmodelos  <- 2\n",
    "# FIN Parametros del script\n",
    "\n",
    "ksemilla  <- 690620\n",
    "\n",
    "#------------------------------------------------------------------------------\n",
    "options(error = function() { \n",
    "  traceback(20); \n",
    "  options(error = NULL); \n",
    "  stop(\"exiting after script error\") \n",
    "})\n",
    "#------------------------------------------------------------------------------\n",
    "#------------------------------------------------------------------------------\n",
    "#Aqui empieza el programa\n",
    "\n",
    "base_dir <- \"~/buckets/b1/\"\n",
    "\n",
    "#creo la carpeta donde va el experimento\n",
    "dir.create( paste0( base_dir, \"exp/\", kexperimento, \"/\"), showWarnings = FALSE )\n",
    "setwd(paste0( base_dir, \"exp/\", kexperimento, \"/\"))   #Establezco el Working Directory DEL EXPERIMENTO\n",
    "\n",
    "#leo la salida de la optimizaciob bayesiana\n",
    "arch_log  <- paste0( base_dir, \"exp/\", kexp_input, \"/BO_log_5meses.txt\" )\n",
    "tb_log  <- fread( arch_log )\n",
    "setorder( tb_log, -ganancia )\n",
    "\n",
    "#leo el nombre del expermento de la Training Strategy\n",
    "#arch_TS  <- paste0( base_dir, \"exp/\", kexp_input, \"/TrainingStrategy.txt\" )\n",
    "#TS  <- readLines( arch_TS, warn=FALSE )\n",
    "\n",
    "#leo el dataset donde voy a entrenar el modelo final\n",
    "arch_dataset  <- paste0( base_dir, \"exp/\", TS, \"/dataset_train_final.csv.gz\" )\n",
    "dataset  <- fread( arch_dataset )\n",
    "\n",
    "#leo el dataset donde voy a aplicar el modelo final\n",
    "arch_future  <- paste0( base_dir, \"exp/\", TS, \"/dataset_future.csv.gz\" )\n",
    "dfuture <- fread( arch_future )\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "dataset[ , clase01 := ifelse( clase_ternaria %in% c(\"BAJA+1\",\"BAJA+2\"), 1, 0 )  ]\n",
    "\n",
    "campos_buenos  <- setdiff( colnames(dataset),\n",
    "                           c( \"clase_ternaria\", \"clase01\") )\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#genero un modelo para cada uno de las modelos_qty MEJORES iteraciones de la Bayesian Optimization\n",
    "for( i in  1:kmodelos )\n",
    "{\n",
    "  parametros  <- as.list( copy( tb_log[ i ] ) )\n",
    "  iteracion_bayesiana  <- parametros$iteracion_bayesiana\n",
    "\n",
    "  arch_modelo  <- paste0( \"modelo_\" ,\n",
    "                          sprintf( \"%02d\", i ),\n",
    "                          \"_\",\n",
    "                          sprintf( \"%03d\", iteracion_bayesiana ),\n",
    "                          \".model\" )\n",
    "\n",
    "\n",
    "  #creo CADA VEZ el dataset de lightgbm\n",
    "  dtrain  <- lgb.Dataset( data=    data.matrix( dataset[ , campos_buenos, with=FALSE] ),\n",
    "                          label=   dataset[ , clase01],\n",
    "                          weight=  dataset[ , ifelse( clase_ternaria %in% c(\"BAJA+2\"), 1.0000001, 1.0)],\n",
    "                          free_raw_data= FALSE\n",
    "                        )\n",
    "\n",
    "  ganancia  <- parametros$ganancia\n",
    "\n",
    "  #elimino los parametros que no son de lightgbm\n",
    "  parametros$experimento  <- NULL\n",
    "  parametros$cols         <- NULL\n",
    "  parametros$rows         <- NULL\n",
    "  parametros$fecha        <- NULL\n",
    "  parametros$prob_corte   <- NULL\n",
    "  parametros$estimulos    <- NULL\n",
    "  parametros$ganancia     <- NULL\n",
    "  parametros$iteracion_bayesiana  <- NULL\n",
    "\n",
    "  #Utilizo la semilla definida en este script\n",
    "  parametros$seed  <- ksemilla\n",
    "  \n",
    "  #genero el modelo entrenando en los datos finales\n",
    "  set.seed( parametros$seed )\n",
    "  modelo_final  <- lightgbm( data= dtrain,\n",
    "                             param=  parametros,\n",
    "                             verbose= -100 )\n",
    "\n",
    "  #grabo el modelo, achivo .model\n",
    "  lgb.save( modelo_final,\n",
    "            file= arch_modelo )\n",
    "\n",
    "  #creo y grabo la importancia de variables\n",
    "  tb_importancia  <- as.data.table( lgb.importance( modelo_final ) )\n",
    "  fwrite( tb_importancia,\n",
    "          file= paste0( \"impo_\", \n",
    "                        sprintf( \"%02d\", i ),\n",
    "                        \"_\",\n",
    "                        sprintf( \"%03d\", iteracion_bayesiana ),\n",
    "                        \".txt\" ),\n",
    "          sep= \"\\t\" )\n",
    "\n",
    "\n",
    "  #genero la prediccion, Scoring\n",
    "  prediccion  <- predict( modelo_final,\n",
    "                          data.matrix( dfuture[ , campos_buenos, with=FALSE ] ) )\n",
    "\n",
    "  tb_prediccion  <- dfuture[  , list( numero_de_cliente, foto_mes ) ]\n",
    "  tb_prediccion[ , prob := prediccion ]\n",
    "\n",
    "\n",
    "  nom_pred  <- paste0( \"pred_\",\n",
    "                       sprintf( \"%02d\", i ),\n",
    "                       \"_\",\n",
    "                       sprintf( \"%03d\", iteracion_bayesiana),\n",
    "                       \".csv\"  )\n",
    "\n",
    "  fwrite( tb_prediccion,\n",
    "          file= nom_pred,\n",
    "          sep= \"\\t\" )\n",
    "\n",
    "\n",
    "  #genero los archivos para Kaggle\n",
    "  cortes  <- seq( from=  7000,\n",
    "                  to=   11000,\n",
    "                  by=     500 )\n",
    "\n",
    "\n",
    "  setorder( tb_prediccion, -prob )\n",
    "\n",
    "  for( corte in cortes )\n",
    "  {\n",
    "    tb_prediccion[  , Predicted := 0L ]\n",
    "    tb_prediccion[ 1:corte, Predicted := 1L ]\n",
    "\n",
    "    nom_submit  <- paste0( kexperimento, \n",
    "                           \"_\",\n",
    "                           sprintf( \"%02d\", i ),\n",
    "                           \"_\",\n",
    "                           sprintf( \"%03d\", iteracion_bayesiana ),\n",
    "                           \"_\",\n",
    "                           sprintf( \"%05d\", corte ),\n",
    "                           \".csv\" )\n",
    "\n",
    "    fwrite(  tb_prediccion[ , list( numero_de_cliente, Predicted ) ],\n",
    "             file= nom_submit,\n",
    "             sep= \",\" )\n",
    "\n",
    "\n",
    "  }\n",
    "\n",
    "\n",
    "  #borro y limpio la memoria para la vuelta siguiente del for\n",
    "  rm( tb_prediccion )\n",
    "  rm( tb_importancia )\n",
    "  rm( modelo_final)\n",
    "  rm( parametros )\n",
    "  rm( dtrain )\n",
    "  gc()\n",
    "}\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "R",
   "language": "R",
   "name": "ir"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "4.2.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
